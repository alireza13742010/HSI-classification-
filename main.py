# -*- coding: utf-8 -*-
"""Hyperspectral_Image_Analysis _ SVM,_KNN,_RF,_XGB1_Indian_pines.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NeI5VW4X-8HhUV_oiQT8RvQEo5-zJ9IQ

# <font color = 'tomato'>Hyperspectral Image Analysis - Classification</font>

## Import Libraries
"""

import plotly.express as px
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
sns.axes_style('whitegrid');
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sn

"""## Download HSI Data

## Read the Data
"""

from google.colab import drive
drive.mount('/content/drive')

from scipy.io import loadmat

def read_HSI():
  #X = loadmat('/content/drive/MyDrive/DATASETS/UTM/test.mat')['test']
  #y = loadmat('/content/drive/MyDrive/DATASETS/UTM/ROI.mat')['ROI']
  X = loadmat('/content/drive/MyDrive/DATASETS/INDIAN PINES/Indian_pines.mat')['indian_pines']
  y = loadmat('/content/drive/MyDrive/DATASETS/INDIAN PINES/Indian_pines_gt.mat')['indian_pines_gt']
  #X = loadmat('/content/drive/MyDrive/DATASETS/PAVIA UNIVERSITY/PaviaU.mat')['paviaU']
  #y = loadmat('/content/drive/MyDrive/DATASETS/PAVIA UNIVERSITY/PaviaU_gt.mat')['paviaU_gt']
  print(f"X shape: {X.shape}\ny shape: {y.shape}")
  return X, y

X, y = read_HSI()

"""### Visualize Bands"""

fig = plt.figure(figsize = (12,12))

for i in range(1, 1+6):
    fig.add_subplot(2,3, i)
    q = np.random.randint(X.shape[2])
    plt.imshow(X[:,:,q], cmap='nipy_spectral')
    plt.axis('off')
    plt.title(f'Band - {q}')
plt.savefig('IP_Bands.png')

"""### Visualize the Ground Truth"""

plt.figure(figsize=(10, 8))
plt.imshow(y, cmap='nipy_spectral')
plt.colorbar()
plt.axis('off')
plt.savefig('IP_GT.png')
plt.show()

"""## Convert the dataset into csv"""

import pandas as pd
import numpy as np

def extract_pixels(X, y):
  q = X.reshape(-1, X.shape[2])
  df = pd.DataFrame(data = q)
  df = pd.concat([df, pd.DataFrame(data = y.ravel())], axis=1)
  df.columns= [f'band{i}' for i in range(1, 1+X.shape[2])]+['class']
  df.to_csv('Dataset.csv')
  return df

df = extract_pixels(X, y)

df.head()

df.info()

df.iloc[:, :-1].describe()

"""## Principal Component Analysis(PCA)

"""

from sklearn.decomposition import PCA

pca = PCA(n_components =X.shape[-1]-1 )

principalComponents = pca.fit_transform(df.iloc[:, :-1].values)

ev=pca.explained_variance_ratio_

plt.figure(figsize=(12, 6))
plt.plot(np.cumsum(ev))
plt.xlabel('Number of components')
plt.ylabel('Cumulative explained variance')


plt.show()

from sklearn.decomposition import PCA
pca = PCA()
pca.fit(df.iloc[:, :-1].values)
cumsum = np.cumsum(pca.explained_variance_ratio_)
d = np.argmax(cumsum >= 0.9999) + 1
print(d)

"""Select best features based on no.of components for PCA"""

pca = PCA(n_components = d)
dt = pca.fit_transform(df.iloc[:, :-1].values)
q = pd.concat([pd.DataFrame(data = dt), pd.DataFrame(data = y.ravel())], axis = 1)
q.columns = [f'PC-{i}' for i in range(1,d+1)]+['class']

q.head()

"""### Display the bands after PCA"""

fig = plt.figure(figsize = (20, 10))

for i in range(1, 1+8):
    fig.add_subplot(2,4, i)
    plt.imshow(q.loc[:, f'PC-{i}'].values.reshape(X.shape[0], X.shape[1]), cmap='nipy_spectral')
    plt.axis('off')
    plt.title(f'Band - {i}')

plt.savefig('IP_PCA_Bands.png')

# saving to .csv
q.to_csv('IP_40_PCA.csv', index=False)

from sklearn.metrics import accuracy_score
x = q[q['class'] != 0]

X = x.iloc[:, :-1].values

y = x.loc[:, 'class'].values
y = pd.DataFrame(y)
y = np.array(y)



from imblearn.over_sampling import SMOTE
smote = SMOTE(sampling_strategy='not minority',random_state=10)
X_sm, y_sm = smote.fit_resample(X, y)
print(X_sm.shape, y_sm.shape)

from imblearn.under_sampling import RandomUnderSampler

OS = RandomUnderSampler(sampling_strategy='auto', random_state=0)
X_rus, y_rus = OS.fit_resample(X, y)
print(X_rus.shape, y_rus.shape)

from imblearn.over_sampling import RandomOverSampler

OS = RandomOverSampler(sampling_strategy='auto', random_state=0)
X_ros, y_ros = OS.fit_resample(X, y)
print(X_ros.shape, y_ros.shape)

df5 = pd.concat([pd.DataFrame(X_sm),pd.DataFrame(X_ros),pd.DataFrame(X_rus)])
print(df5.shape)
target5 = pd.concat([pd.DataFrame(y_sm),pd.DataFrame(y_ros),pd.DataFrame(y_rus)])
print(target5.shape)

X_train, X_test, y_train, y_test = train_test_split(np.array(df5 ), np.array(target5) , test_size=0.3, random_state=42)

"""## Support Vector Machine(SVM)

"""

svm =  SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)

svm.fit(X_train, y_train)

ypred = svm.predict(X_test)
ypred1 = svm.predict(X_train)
print("Accuracy for train set with SVM:",accuracy_score(y_train,ypred1))
print("Accuracy for test set with SVM:",accuracy_score(y_test, ypred ))

np.unique(y)

data = confusion_matrix(y_test, ypred)
df_cm = pd.DataFrame(data)
df_cm.index.name = 'Actual'
df_cm.columns.name = 'Predicted'
plt.figure(figsize = (10,8))
sn.set(font_scale=1.4)#for label size
sn.heatmap(df_cm, cmap="Reds", annot=True,annot_kws={"size": 16}, fmt='d')
plt.savefig('cmap.png', dpi=300)

print(classification_report(y_test, ypred))

q.head()

x = q[q['class'] != 0]

X = x.iloc[:, :-1].values

y = x.loc[:, 'class'].values

names = ["Alfalfa","Corn-notill","Corn","Grass-pasture","Grass-trees","Grass-pasture-mowed","Hay-windrowed","Oats","Soybean-notill","Soybean-mintill","Soybean-clean","Wheat","Woods","Buildings-Grass-Trees-Drives","Stone-Steel-Towers"]
print(X.shape)
print(y.shape)
y = pd.DataFrame(y)
y =y.replace([15], 5)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11, stratify=y)

svm =  SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)

svm.fit(X_train, y_train)

ypred = svm.predict(X_test)

print(y.value_counts())

data = confusion_matrix(y_test, ypred)
df_cm = pd.DataFrame(data, columns=np.unique(names), index = np.unique(names))
df_cm.index.name = 'Actual'
df_cm.columns.name = 'Predicted'
plt.figure(figsize = (10,8))
sn.set(font_scale=1.4)#for label size
sn.heatmap(df_cm, cmap="Reds", annot=True,annot_kws={"size": 16}, fmt='d')
plt.savefig('cmap.png', dpi=300)

print(classification_report(y_test, ypred, target_names = names))

l=[]
for i in range(q.shape[0]):
  if q.iloc[i, -1] == 0:
    l.append(0)
  else:
    l.append(svm.predict(q.iloc[i, :-1].values.reshape(1, -1)))

clmap = np.array(l).reshape(1061, 700).astype('float')
plt.figure(figsize=(20, 20))
plt.imshow(clmap, cmap='nipy_spectral')
plt.colorbar()
plt.axis('off')
plt.savefig('IP_cmap.png')
plt.show()

"""## K Nearest Neighbour(KNN)"""

from sklearn.cluster import MiniBatchKMeans
for i in range(2,20):
  n_clusters=i
  minibatch_kmeans = MiniBatchKMeans(n_clusters)
  minibatch_kmeans.fit(X_train)
  from sklearn.metrics import silhouette_score
  print(f'silhouette_score for {n_clusters} of cluster',silhouette_score(X_train, minibatch_kmeans.labels_))

from sklearn.neighbors import KNeighborsClassifier

#Create KNN Classifier
knn = KNeighborsClassifier(n_neighbors=5)

#Train the model using the training sets
knn.fit(X_train, y_train)

from sklearn import metrics
y_pred = knn.predict(X_train)
y_pred_test = knn.predict(X_test)
print("Accuracy for train set:",metrics.accuracy_score(y_train, y_pred))
print("Accuracy for test set:",metrics.accuracy_score(y_test, y_pred_test))

print("Result on KNN")
print(classification_report(y_pred_test, ypred))

probas = knn.predict_proba(X_test)
probas.shape

y_testsm = y_test.reshape(y_test.shape[0])
y_predsm =y_pred_test.reshape(y_pred_test.shape[0])
print(y_testsm.shape,y_predsm.shape)

from sklearn.preprocessing import OneHotEncoder
enc = OneHotEncoder(handle_unknown='ignore')
probas1= enc.fit_transform(y_test.reshape(-1,1)).toarray()
print(probas1.shape)

!pip install scikit-plot

import scikitplot as skplt
import matplotlib.pyplot as plt

plt.style.use('ggplot')
skplt.metrics.plot_confusion_matrix(y_test,y_predsm, normalize=True, cmap='hot_r',figsize=[10,10])
plt.show()

plt.style.use('ggplot')
skplt.metrics.plot_roc(y_test,probas1,title="ROC Curves with KNN Classifeir", cmap='Blues', figsize=[7,7])
plt.show()

"""## Random Forest"""

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier

RandomForest=RandomForestClassifier(max_depth=200,max_features=20,min_samples_leaf=3,min_samples_split=12,n_estimators=90)
RandomForest.fit(X_train, y_train)
y_pred_trainsm_rnd = RandomForest.predict(X_train)
y_predsm_rnd = RandomForest.predict(X_test)
accuracy_trainsm = accuracy_score(y_train, y_pred_trainsm_rnd)
accuracysm = accuracy_score(y_test, y_predsm_rnd)
print("Accuracysm of random_forest: %.2f%%" % (accuracysm * 100.0))
print("Accuracy trainsm of random_forest: %.2f%%" % (accuracy_trainsm * 100.0))

print("Result on RF")
print(classification_report(y_predsm_rnd, ypred))

probas = RandomForest.predict_proba(X_test)
print(probas.shape)

y_testsm = y_test.reshape(y_test.shape[0])
y_predsm = y_predsm_rnd.reshape(y_testsm.shape[0])
print(y_testsm.shape,y_predsm.shape)

plt.style.use('ggplot')
skplt.metrics.plot_confusion_matrix(y_testsm,y_predsm, normalize=True, cmap='hot_r',figsize=[10,10])
plt.show()

skplt.metrics.plot_roc(y_testsm,probas,title="ROC Curves with Random Forest", cmap='Blues', figsize=[7,7])
plt.show()

"""## Exreme Boost classifier"""

from xgboost import XGBClassifier

model=XGBClassifier(n_estimators=100,max_depth=40,learning_rate=0.8)

model.fit(X_train, y_train)
y_pred_trainsm = model.predict(X_train)
y_predsm = model.predict(X_test)
accuracy_trainsm = accuracy_score(y_train, y_pred_trainsm)
accuracysm = accuracy_score(y_test, y_predsm)
print("Accuracysm: %.2f%%" % (accuracysm * 100.0))
print("Accuracy trainsm: %.2f%%" % (accuracy_trainsm * 100.0))



!pip install scikit-plot

import scikitplot as skplt
import matplotlib.pyplot as plt

print("Result on XGB")
print(classification_report(y_test, y_predsm))

probas = model.predict_proba(X_test)

y_testsm = y_test.reshape(y_test.shape[0])
y_predsm = y_predsm.reshape(y_testsm.shape[0])
print(y_testsm.shape,y_predsm.shape)

plt.style.use('ggplot')
skplt.metrics.plot_confusion_matrix(y_testsm,y_predsm, normalize=True, cmap='hot_r',figsize=[10,10])
plt.show()

from sklearn.preprocessing import OneHotEncoder
enc = OneHotEncoder(handle_unknown='ignore')

skplt.metrics.plot_roc(y_testsm,enc.fit_transform(y_predsm.reshape(-1,1)).toarray(),title="ROC Curves with XGB Classifeir", cmap='Blues', figsize=[7,7])
plt.show()

names = ['Alfalfa','Corn-notill','Corn-mintill','Corn','Grass-pasture','Grass-trees','Grass-pasture-mowed'
,'Hay-windrowed','Oats','Soybean-notill','Soybean-mintill','Soybean-clean','Wheat','Wood','Building Grass Tree drivers'
,'Stone-Steal-Towers']

l=[]
for i in range(q.shape[0]):
  if q.iloc[i, -1] == 0:
    l.append(0)
  else:
    l.append(model.predict(q.iloc[i, :-1].values.reshape(1, -1)))

clmap = np.array(l).reshape(145, 145).astype('float')
plt.figure(figsize=(20, 20))
plt.imshow(clmap, cmap='nipy_spectral')
plt.colorbar()
plt.axis('off')
plt.savefig('IP_cmap.png')
plt.show()
